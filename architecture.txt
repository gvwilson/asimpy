# asimpy Implementation

## Core Concept

This framework simulates systems where events occur at discrete points in time. The simulation maintains a virtual clock and executes events in chronological order. Unlike real-time systems, the simulation jumps directly from one event time to the next, skipping empty intervals.

## The Async/Await Mechanism

Python's `async`/`await` syntax enables cooperative multitasking without threads. Functions defined with `async def` return coroutine objects when called. These coroutines can be paused at `await` points and later resumed.

When a coroutine executes `await expr`, it:
1. Yields the awaited object to its caller
2. Suspends execution at that point
3. Resumes later when `send(value)` is called on the coroutine
4. Returns the value passed to `send()` as the result of the `await` expression

The framework uses this mechanism to pause processes at specific simulation times and resume them when their events trigger.

## Environment: The Event Scheduler

The `Environment` class maintains the simulation state:
- `_now`: current simulation time
- `_pending`: priority queue of scheduled callbacks ordered by time

The `schedule(time, callback)` method adds callbacks to the queue. The `_Pending` dataclass includes a serial number to ensure stable ordering when multiple events occur at the same time.

The `run()` method executes the main simulation loop:
1. Extract the earliest pending event from the heap
2. If an `until` parameter is specified and the event time exceeds it, stop
3. Execute the callback
4. If the callback doesn't return `NO_TIME` and the event time exceeds current time, advance the clock

The `NO_TIME` sentinel prevents time advancement when events are cancelled.

## Events: Synchronization Primitives

The `Event` class represents something that will complete in the future. It maintains:
- `_triggered`: whether the event has completed
- `_cancelled`: whether the event was cancelled
- `_value`: the result value
- `_waiters`: processes waiting for this event

When `succeed(value)` is called:
1. Set `_triggered` to true and store the value
2. Call `resume(value)` on all waiting processes
3. Clear the waiters list

The `_add_waiter(proc)` method handles two cases:
- If already triggered, immediately call `proc.resume(value)`
- Otherwise, add to waiters list (unless cancelled)

Events implement `__await__()` which yields `self`. This allows `await event` syntax in coroutines.

## Process: Active Simulation Entities

The `Process` class uses coroutines to implement simulation entities with behavior over time. Construction:
1. Store environment reference
2. Call `init()` for subclass-specific setup
3. Create coroutine by calling `run()`
4. Schedule immediate execution of `_loop()`

The `_loop()` method drives coroutine execution:
1. If an interrupt is pending, throw it into the coroutine via `throw()`
2. Otherwise, send the value into the coroutine via `send()`
3. Receive the yielded event
4. Register this process as a waiter on that event
5. When `StopIteration` is raised (coroutine completes), mark as done
6. If any other exception occurs, mark as done and re-raise

When `resume(value)` is called (by an event completing), it schedules another `_loop()` iteration with the provided value. This continues the coroutine past its `await` point.

The interrupt mechanism sets `_interrupt` and schedules immediate execution. The next `_loop()` iteration throws the interrupt into the coroutine, which can be caught with `try`/`except`.

## Timeout: Time-Based Events

A `Timeout` schedules a callback at a future time. The `_fire()` method:
- Returns `NO_TIME` if cancelled (preventing time advancement)
- Otherwise calls `succeed()` to trigger the event

This prevents cancelled timeouts from advancing simulation time.

## Queue: Process Communication

The `Queue` class enables processes to exchange data:
- `_items`: buffered items
- `_getters`: processes waiting for items

On `put(item)`:
- If processes are waiting, directly `succeed()` the first waiter's event with the item
- Otherwise append to buffer

On `get()`:
- If items exist, create an event that immediately succeeds with the first item
- Otherwise create an event and add to getters list

The `_on_cancel` callback handles cancellation by returning items to the queue's front, maintaining FIFO order.

`PriorityQueue` uses `heapq` operations to maintain ordering. Items must be comparable. The `get()` operation pops the minimum element; `put()` pushes onto the heap and potentially satisfies a waiting getter.

## Resource: Capacity-Limited Sharing

The `Resource` class limits concurrent access:
- `capacity`: maximum concurrent users
- `_count`: current users
- `_waiters`: processes waiting for availability

On `acquire()`:
- If below capacity, call `_acquire_available()` which increments count and immediately succeeds
- Otherwise call `_acquire_unavailable()` which adds to waiters

On `release()`:
- Decrement count
- If waiters exist, succeed the first one (it will then increment count in its completion logic)

The `_on_cancel` callbacks handle cancellation by either decrementing the count or removing from the waiters list.

The context manager protocol (`__aenter__`/`__aexit__`) automates acquire/release pairing.

## AllOf: Waiting for Multiple Events

`AllOf` succeeds when all provided events complete. It:
1. Converts each input to an event
2. Registers a `_AllOfWatcher` on each
3. Accumulates results in `_results` dictionary
4. Succeeds when all results collected

Each watcher calls `_child_done(key, value)` when its event completes. This stores the result and checks if all events are done.

## FirstOf: Racing Multiple Events

`FirstOf` succeeds when any provided event completes first. It:
1. Converts each input to an event
2. Registers a `_FirstOfWatcher` on each
3. On first completion, cancels all other events
4. Succeeds with tuple of (key, value)

The `_done` flag prevents multiple completions. When `_child_done()` is called, it checks this flag, sets it, cancels losers, and succeeds.

## Barrier: Synchronizing Multiple Processes

The `Barrier` holds processes until explicitly released:
- `wait()` creates an event and adds it to waiters
- `release()` succeeds all waiting events and clears the list

This allows multiple processes to pause at a synchronization point.

## Control Flow Example

Consider a process that waits 5 time units:

```python
class Waiter(Process):
    async def run(self):
        await self.timeout(5)
        print("done")
```

Execution sequence:
1. Construction calls `__init__()`, creates coroutine from `run()`, schedules immediate `_loop()`
2. First `_loop()` calls `send(None)`, coroutine executes to `await`, yields `Timeout` event
3. `_loop()` registers this process as waiter on the timeout
4. Timeout scheduled callback at time 5
5. At time 5, callback fires, calls `succeed()` on timeout
6. Timeout calls `resume()` on this process
7. `resume()` schedules immediate `_loop()` with value `None`
8. `_loop()` calls `send(None)`, coroutine continues past `await`, prints, raises `StopIteration`
9. Process marked done

## Coroutine Adaptation

The `ensure_event()` function handles both Event objects and bare coroutines. For coroutines, it creates a `_Runner` process that:
1. Awaits the coroutine
2. On completion, succeeds an event with the result

This allows `AllOf` and `FirstOf` to accept both events and coroutines.

## Requirements for Correctness

**Event waiter notification must occur before clearing the list.** If the list were cleared first, waiters couldn't be resumed.

**The `_Pending` serial number is necessary** because heap operations require total ordering. Without it, callbacks (functions) would be compared, causing errors.

**Cancelled events must not advance time.** The `NO_TIME` sentinel prevents this. Otherwise, cancelled timeouts would create gaps in the simulation timeline.

**Process interrupt checking must occur before coroutine sends.** This ensures interrupts are handled immediately rather than being delayed until the next event.

**Queue cancellation handlers must remove items or waiters.** Without this, cancelled gets would leave processes in the waiters list indefinitely, and cancelled items would disappear from the queue.

**Resource cancellation handlers must adjust state.** Without them, cancelled acquires would permanently reduce available capacity or leave ghost waiters.

**FirstOf must cancel losing events.** Otherwise, those events would remain active and potentially trigger later, affecting system state.

**AllOf must track completion.** Without checking if all events are done, it would succeed prematurely.

## Rationale for Accepting Both Events and Coroutines

`AllOf` and `FirstOf` must accept coroutines in addition to events because of how Python's async/await syntax works and what users naturally write.

### The Syntactic Issue

When a user writes:

```python
await AllOf(env, a=queue.get(), b=resource.acquire())
```

The expressions `queue.get()` and `resource.acquire()` are calls to `async def` functions. In Python, calling an async function **does not execute it**—it returns a coroutine object.

Without coroutine support, this code would fail because `queue.get()` returns a coroutine, not an Event.

### Alternative User Syntax Would Be Awkward

If `AllOf` only accepted events, users would need to write:

```python
# Manually create events
evt_a = Event(env)
evt_b = Event(env)

# Manually create runners
_Runner(env, evt_a, queue.get())
_Runner(env, evt_b, resource.acquire())

# Now use the events
await AllOf(env, a=evt_a, b=evt_b)
```

This is verbose and exposes internal implementation details.

### The Adapter Pattern

The `ensure_event()` function and `_Runner` class solve this by:

1. Detecting whether an object is already an Event
2. If it's a coroutine, wrapping it in a throwaway Process (`_Runner`) that:
   - Executes the coroutine
   - Captures its result
   - Succeeds an Event with that result
3. Returning the Event

This allows natural syntax while maintaining the internal requirement that `AllOf` and `FirstOf` only work with Event objects.

### Why Not Just Use Coroutines Everywhere?

Events must be the internal primitive because:

1. **Events can be triggered externally.** A `Timeout` schedules a callback that later calls `succeed()`. A coroutine cannot be "succeeded" from outside—it must run to completion.

2. **Events support multiple waiters.** Multiple processes can `await` the same event. A coroutine can only be awaited once.

3. **Events can be cancelled.** The framework needs to cancel losing events in `FirstOf`. Coroutines don't have a cancellation mechanism that prevents their execution.

4. **Events decouple triggering from waiting.** The thing that creates an event (like `Timeout.__init__()`) is separate from the thing that waits for it. With coroutines, creation and execution are coupled.

The adapter pattern provides user convenience (accepting coroutines) while preserving the necessary internal semantics (operating on events).
